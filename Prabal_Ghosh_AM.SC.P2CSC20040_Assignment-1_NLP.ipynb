{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prabal Ghosh   Roll-AM.SC.P2CSC20040  Assignment-1 (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Write a paragraph about any chatbot and save this as chabot.text file.\n",
    "\n",
    "\n",
    "# 2. Read and display this file with Python program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI chatbots can improve their functionality and become smarter as time progresses. They can learn new features and adapt as required. Intelligent chatbots become more intelligent over time using NLP and machine learning algorithms.\n",
      "Human feedback is essential to the growth and advancement of an AI chatbot. Developers can then review the feedback and make the relevant changes to improve the functionality of the chatbot.Intelligent chatbots are a game changer for organizations looking to intelligently interact with their customers in an automated manner.\n",
      "The process would be genuinely tedious and cumbersome to create a rule-based chatbot with the same level of understanding and intuition as an advanced AI chatbot. Understanding goals of the user is extremely important whenÂ designing a chatbot conversation.\n",
      "The chatbot is provided with a large amount of data that the algorithms process and find the model that give the correct answers.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file=open(\"C:/Users/Prabal Ghosh/Desktop/chatbot.txt\")\n",
    "text=file.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extract sentences and words from this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentTokens=sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AI chatbots can improve their functionality and become smarter as time progresses.',\n",
       " 'They can learn new features and adapt as required.',\n",
       " 'Intelligent chatbots become more intelligent over time using NLP and machine learning algorithms.',\n",
       " 'Human feedback is essential to the growth and advancement of an AI chatbot.',\n",
       " 'Developers can then review the feedback and make the relevant changes to improve the functionality of the chatbot.Intelligent chatbots are a game changer for organizations looking to intelligently interact with their customers in an automated manner.',\n",
       " 'The process would be genuinely tedious and cumbersome to create a rule-based chatbot with the same level of understanding and intuition as an advanced AI chatbot.',\n",
       " 'Understanding goals of the user is extremely important when\\xa0designing a chatbot conversation.',\n",
       " 'The chatbot is provided with a large amount of data that the algorithms process and find the model that give the correct answers.']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AI', 'chatbots', 'can', 'improve', 'their', 'functionality', 'and', 'become', 'smarter', 'as', 'time', 'progresses', '.', 'They', 'can', 'learn', 'new', 'features', 'and', 'adapt', 'as', 'required', '.', 'Intelligent', 'chatbots', 'become', 'more', 'intelligent', 'over', 'time', 'using', 'NLP', 'and', 'machine', 'learning', 'algorithms', '.', 'Human', 'feedback', 'is', 'essential', 'to', 'the', 'growth', 'and', 'advancement', 'of', 'an', 'AI', 'chatbot', '.', 'Developers', 'can', 'then', 'review', 'the', 'feedback', 'and', 'make', 'the', 'relevant', 'changes', 'to', 'improve', 'the', 'functionality', 'of', 'the', 'chatbot.Intelligent', 'chatbots', 'are', 'a', 'game', 'changer', 'for', 'organizations', 'looking', 'to', 'intelligently', 'interact', 'with', 'their', 'customers', 'in', 'an', 'automated', 'manner', '.', 'The', 'process', 'would', 'be', 'genuinely', 'tedious', 'and', 'cumbersome', 'to', 'create', 'a', 'rule-based', 'chatbot', 'with', 'the', 'same', 'level', 'of', 'understanding', 'and', 'intuition', 'as', 'an', 'advanced', 'AI', 'chatbot', '.', 'Understanding', 'goals', 'of', 'the', 'user', 'is', 'extremely', 'important', 'when', 'designing', 'a', 'chatbot', 'conversation', '.', 'The', 'chatbot', 'is', 'provided', 'with', 'a', 'large', 'amount', 'of', 'data', 'that', 'the', 'algorithms', 'process', 'and', 'find', 'the', 'model', 'that', 'give', 'the', 'correct', 'answers', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "wordTokens=word_tokenize(text)\n",
    "print(wordTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordTokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. If there are any stop-words, remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.extend([\"''\",'.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding  all stop words from the wordtokens \n",
    "new_list=[]\n",
    "Count=0;\n",
    "for i in wordTokens:\n",
    "    if i.lower() in stop_words:\n",
    "        \n",
    "        new_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['can', 'their', 'and', 'as', '.', 'They', 'can', 'and', 'as', '.', 'more', 'over', 'and', '.', 'is', 'to', 'the', 'and', 'of', 'an', '.', 'can', 'then', 'the', 'and', 'the', 'to', 'the', 'of', 'the', 'are', 'a', 'for', 'to', 'with', 'their', 'in', 'an', '.', 'The', 'be', 'and', 'to', 'a', 'with', 'the', 'same', 'of', 'and', 'as', 'an', '.', 'of', 'the', 'is', 'when', 'a', '.', 'The', 'is', 'with', 'a', 'of', 'that', 'the', 'and', 'the', 'that', 'the', '.']\n"
     ]
    }
   ],
   "source": [
    "print(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of unique stop words from the wordtokens of my corpus\n",
    "removed_stop_word=[]\n",
    "Count=0;\n",
    "for i in wordTokens:\n",
    "    if i.lower() in stop_words:\n",
    "        if i not in removed_stop_word:\n",
    "             removed_stop_word.append(i)\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['can', 'their', 'and', 'as', '.', 'They', 'more', 'over', 'is', 'to', 'the', 'of', 'an', 'then', 'are', 'a', 'for', 'with', 'in', 'The', 'be', 'same', 'when', 'that']\n"
     ]
    }
   ],
   "source": [
    " print(removed_stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Count number of stop words and non stop-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop word count =  70\n"
     ]
    }
   ],
   "source": [
    "non_stop_words_list=[]\n",
    "Count=0;\n",
    "for i in wordTokens:\n",
    "    if i.lower() not in stop_words:\n",
    "        non_stop_words_list.append(i)\n",
    "    else:\n",
    "        Count+=1\n",
    "print(\"stop word count = \",Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non stop words are:\n",
      "\n",
      " \n",
      "['AI', 'chatbots', 'improve', 'functionality', 'become', 'smarter', 'time', 'progresses', 'learn', 'new', 'features', 'adapt', 'required', 'Intelligent', 'chatbots', 'become', 'intelligent', 'time', 'using', 'NLP', 'machine', 'learning', 'algorithms', 'Human', 'feedback', 'essential', 'growth', 'advancement', 'AI', 'chatbot', 'Developers', 'review', 'feedback', 'make', 'relevant', 'changes', 'improve', 'functionality', 'chatbot.Intelligent', 'chatbots', 'game', 'changer', 'organizations', 'looking', 'intelligently', 'interact', 'customers', 'automated', 'manner', 'process', 'would', 'genuinely', 'tedious', 'cumbersome', 'create', 'rule-based', 'chatbot', 'level', 'understanding', 'intuition', 'advanced', 'AI', 'chatbot', 'Understanding', 'goals', 'user', 'extremely', 'important', 'designing', 'chatbot', 'conversation', 'chatbot', 'provided', 'large', 'amount', 'data', 'algorithms', 'process', 'find', 'model', 'give', 'correct', 'answers']\n"
     ]
    }
   ],
   "source": [
    "print(\"Non stop words are:\\n\\n \")\n",
    "print(non_stop_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " stop word count =  70\n"
     ]
    }
   ],
   "source": [
    "new_list=[]\n",
    "for i in wordTokens:\n",
    "    if i.lower()  in stop_words:\n",
    "        new_list.append(i)\n",
    "print(\" stop word count = \",len(new_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non stop word count =  83\n"
     ]
    }
   ],
   "source": [
    "new_list=[]\n",
    "for i in wordTokens:\n",
    "    if i.lower() not in stop_words:\n",
    "        new_list.append(i)\n",
    "print(\"non stop word count = \",len(new_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text after stop word removal: \n",
      "\n",
      "\n",
      "AI chatbots improve functionality become smarter time progresses. They learn new features adapt required. Intelligent chatbots become intelligent time using NLP machine learning algorithms.\n",
      "Human feedback essential growth advancement AI chatbot. Developers review feedback make relevant changes improve functionality chatbot.Intelligent chatbots game changer organizations looking intelligently interact customers automated manner.\n",
      "The process would genuinely tedious cumbersome create rule-based chatbot level understanding intuition advanced AI chatbot. Understanding goals user extremely important whenÂ designing chatbot conversation.\n",
      "The chatbot provided large amount data algorithms process find model give correct answers.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_list = list(text.split(\" \"))\n",
    "removed_text=[w for w in text_list if w not in stop_words]\n",
    "final_result_text=' '.join(removed_text)\n",
    "print(\"final text after stop word removal: \\n\\n\")\n",
    "print(final_result_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Translate any ten of these words into your native language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    " # pip install translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "à¦¸à¦¿à¦¤à¦¾ à¦ à¦°à¦¾à¦£à§ à¦à¦à¦à¦¿ à¦à¦¾à¦¨ à¦à¦¾à¦¯à¦¼\n"
     ]
    }
   ],
   "source": [
    "from translate import Translator\n",
    "\n",
    "translator= Translator(to_lang=\"bengali\")\n",
    "\n",
    "translation = translator.translate(\" sita and rani sing a song \")\n",
    "\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI  ----->  à¦à¦à¦\n",
      "chatbots  ----->  chatbots\n",
      "improve  ----->  à¦à¦¨à§à¦¨à¦¤à¦¿\n",
      "functionality  ----->  à¦à¦¾à¦°à§à¦¯à¦à¦¾à¦°à¦¿à¦¤à¦¾\n",
      "become  ----->  à¦¹à¦¯à¦¼à§\n",
      "smarter  ----->  à¦¸à§à¦®à¦¾à¦°à§à¦\n",
      "time  ----->  à¦¸à¦®à¦¯à¦¼\n",
      "progresses.  ----->  à¦à¦à§à¦°à¦à¦¤à¦¿\n",
      "They  ----->  à¦¤à¦¾à¦°à¦¾\n",
      "learn  ----->  You are about to translate the &apos;Reset&apos; COMMAND, there are some rules on how to translate it. Please see http: // edu. kde. org/ kturtle/ translator. php to learn how to properly translate it.\n",
      "new  ----->  à¦¨à¦¤à§à¦¨\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in final_result_text.split(\" \")[0:11]:\n",
    "    translatedword = translator.translate(i)\n",
    "    print(i ,\" -----> \",translatedword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI  ----->  à¦à¦à¦\n",
      "chatbots  ----->  chatbots\n",
      "improve  ----->  à¦à¦¨à§à¦¨à¦¤à¦¿\n",
      "functionality  ----->  à¦à¦¾à¦°à§à¦¯à¦à¦¾à¦°à¦¿à¦¤à¦¾\n",
      "become  ----->  à¦¹à¦¯à¦¼à§\n",
      "smarter  ----->  à¦¸à§à¦®à¦¾à¦°à§à¦\n",
      "time  ----->  à¦¸à¦®à¦¯à¦¼\n",
      "progresses  ----->  à¦à¦à§à¦°à¦à¦¤à¦¿\n",
      "learn  ----->  MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  14 HOURS 53 MINUTES 24 SECONDSVISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE\n",
      "new  ----->  MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  14 HOURS 53 MINUTES 23 SECONDSVISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE\n",
      "features  ----->  MYMEMORY WARNING: YOU USED ALL AVAILABLE FREE TRANSLATIONS FOR TODAY. NEXT AVAILABLE IN  14 HOURS 53 MINUTES 23 SECONDSVISIT HTTPS://MYMEMORY.TRANSLATED.NET/DOC/USAGELIMITS.PHP TO TRANSLATE MORE\n"
     ]
    }
   ],
   "source": [
    "for i in non_stop_words_list[0:11]:\n",
    "    translatedword = translator.translate(i)\n",
    "    print(i ,\" -----> \",translatedword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. If there are any spelling mistakes, remove the identified ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyspellchecker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrected words are :\n",
      "\n",
      "chatbots  ------>  chariots\n",
      "NLP  ------>  nap\n",
      "chatbot  ------>  chariot\n"
     ]
    }
   ],
   "source": [
    "corrected_word=[]\n",
    "print(\"corrected words are :\\n\")\n",
    "for i in wordTokens:\n",
    "    corrected=spell.correction(i)\n",
    "    if(i !=corrected):\n",
    "        if corrected not in corrected_word:\n",
    "            corrected_word.append(corrected)\n",
    "            print(i,\" ------> \",corrected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrected text is :\n",
      "\n",
      "\n",
      "['AI', 'chariots', 'can', 'improve', 'their', 'functionality', 'and', 'become', 'smarter', 'as', 'time', 'progresses', '.', 'They', 'can', 'learn', 'new', 'features', 'and', 'adapt', 'as', 'required', '.', 'Intelligent', 'chariots', 'become', 'more', 'intelligent', 'over', 'time', 'using', 'nap', 'and', 'machine', 'learning', 'algorithms', '.', 'Human', 'feedback', 'is', 'essential', 'to', 'the', 'growth', 'and', 'advancement', 'of', 'an', 'AI', 'chariot', '.', 'Developers', 'can', 'then', 'review', 'the', 'feedback', 'and', 'make', 'the', 'relevant', 'changes', 'to', 'improve', 'the', 'functionality', 'of', 'the', 'chatbot.Intelligent', 'chariots', 'are', 'a', 'game', 'changer', 'for', 'organizations', 'looking', 'to', 'intelligently', 'interact', 'with', 'their', 'customers', 'in', 'an', 'automated', 'manner', '.', 'The', 'process', 'would', 'be', 'genuinely', 'tedious', 'and', 'cumbersome', 'to', 'create', 'a', 'rule-based', 'chariot', 'with', 'the', 'same', 'level', 'of', 'understanding', 'and', 'intuition', 'as', 'an', 'advanced', 'AI', 'chariot', '.', 'Understanding', 'goals', 'of', 'the', 'user', 'is', 'extremely', 'important', 'when', 'designing', 'a', 'chariot', 'conversation', '.', 'The', 'chariot', 'is', 'provided', 'with', 'a', 'large', 'amount', 'of', 'data', 'that', 'the', 'algorithms', 'process', 'and', 'find', 'the', 'model', 'that', 'give', 'the', 'correct', 'answers', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"corrected text is :\\n\\n\")\n",
    "correctedText=[]\n",
    "for i in wordTokens:\n",
    "    corrected=spell.correction(i)\n",
    "    if(i==corrected):\n",
    "        correctedText.append(i)\n",
    "    else:\n",
    "        correctedText.append(corrected)\n",
    "print(correctedText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
